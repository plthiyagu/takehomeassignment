# -*- coding: utf-8 -*-
"""Grainger_Assignment_latest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ru97XhcT1StSmp3gUG5WdVly-Kgw3HB9
"""

!apt-get install git-lfs  # or: !git lfs install
!git lfs install
!pip install faiss-cpu faiss-gpu-cu12 transformers sentence-transformers

import os
import warnings
import numpy as np
import pandas as pd
from tqdm.auto import tqdm
import faiss
import torch
from sentence_transformers import SentenceTransformer, CrossEncoder
warnings.filterwarnings('ignore')

if not os.path.exists("esci-data"):
    !git clone https://github.com/amazon-science/esci-data.git

MODELS = {
    "bge-small-en": "BAAI/bge-small-en",
    "mpnet-base-v2": "sentence-transformers/all-mpnet-base-v2"
}
RERANKER_MODEL = "cross-encoder/ms-marco-MiniLM-L-12-v2"
USE_RERANKER = True
PRODUCT_LOCALE = "us"
ESCI_LABEL = "E"
N_QUERIES = 50
N_ROWS = 500
TOP_K = 10
RANDOM_STATE = 42

def read_input_files(base_path="esci-data/shopping_queries_dataset"):
    print("\nStep 1 Reading input files")
    files = {
        "examples": os.path.join(base_path, "shopping_queries_dataset_examples.parquet"),
        "products": os.path.join(base_path, "shopping_queries_dataset_products.parquet"),
    }
    data = {}
    for name, path in files.items():
        print(f"Loading {name} from {path}")
        df = pd.read_parquet(path) if path.endswith(".parquet") else pd.read_csv(path)
        print(f"Shape: {df.shape}")
        data[name] = df
    return data

def filter_examples(df):
    print("\nStep 2 Filtering examples")
    filtered = df[(df['product_locale'] == PRODUCT_LOCALE) & (df['esci_label'] == ESCI_LABEL)].copy()
    print(f"Filtered rows: {filtered.shape[0]}")
    return filtered

def sample_queries_and_rows(df):
    print("\nStep 3 Sampling queries and rows")
    np.random.seed(RANDOM_STATE)
    unique_queries = df['query'].unique()
    print(f"Total unique queries: {len(unique_queries)}")
    selected_queries = np.random.choice(unique_queries, N_QUERIES, replace=False)
    print(f"Selected queries: {len(selected_queries)}")
    df_filtered = df[df['query'].isin(selected_queries)]
    df_sampled = df_filtered.sample(min(N_ROWS, len(df_filtered)), random_state=RANDOM_STATE).reset_index(drop=True)
    print(f"Sampled rows: {df_sampled.shape[0]}")
    return df_sampled, selected_queries

def create_product_text(df_products):
    print("\nStep 4 Creating combined product text")
    text_cols = [c for c in df_products.columns if c.startswith("product_")]
    print(f"Text columns: {text_cols}")
    df = df_products.copy()
    df['combined_text'] = df[text_cols].astype(str).apply(
        lambda row: ' | '.join([v for v in row if v and v != 'nan']), axis=1
    )
    print(f"Created combined_text for {len(df)} products")
    return df

def generate_embeddings(df_products, model):
    print(f"Generating embeddings for {len(df_products)} products")
    embeddings = model.encode(df_products['combined_text'].tolist(),
                               batch_size=64, show_progress_bar=True, convert_to_numpy=True)
    print(f"Embeddings shape: {embeddings.shape}")
    return embeddings.astype(np.float32)

def create_ground_truth(df_sampled, df_products):
    print("\nStep 5 Creating ground truth mapping")
    pid_to_idx = {pid: i for i, pid in enumerate(df_products['product_id'])}
    ground_truth = {}
    for query in df_sampled['query'].unique():
        indices = [pid_to_idx[pid] for pid in df_sampled[df_sampled['query'] == query]['product_id'] if pid in pid_to_idx]
        if indices:
            ground_truth[query] = set(indices)
    print(f"  Ground truth created for {len(ground_truth)} queries")
    return ground_truth

def build_search_index(embeddings):
    print("\nStep 6 Building FAISS index")
    faiss.normalize_L2(embeddings)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)
    print(f"Index built with {embeddings.shape[0]} vectors of dim {dim}")
    return index

def perform_search(index, query_embeddings, top_k=TOP_K):
    print(f"Performing FAISS search for {len(query_embeddings)} queries...")
    faiss.normalize_L2(query_embeddings)
    scores, indices = index.search(query_embeddings, top_k)
    print(f"Search complete. Returned shape: {indices.shape}")
    return scores, indices

def rerank_results(queries, search_indices, df_products_text):
    print("\n Step 7 Applying cross-encoder re-ranking...")
    reranker = CrossEncoder(RERANKER_MODEL)
    reranked_indices = []
    for i, (q, retrieved_idxs) in enumerate(zip(queries, search_indices), 1):
        candidates = [(q, df_products_text.iloc[idx]['combined_text']) for idx in retrieved_idxs]
        scores = reranker.predict(candidates)
        sorted_pairs = sorted(zip(retrieved_idxs, scores), key=lambda x: x[1], reverse=True)
        reranked_indices.append([idx for idx, _ in sorted_pairs])
        if i % 10 == 0 or i == len(queries):
            print(f"    Reranked {i}/{len(queries)} queries")
    print("Re-ranking complete.")
    return np.array(reranked_indices)

def evaluate(search_indices, queries, ground_truth, k_values=[1, 5, 10]):
    print("\nStep 8 Evaluating results...")
    results = {f"hits@{k}": [] for k in k_values}
    mrr_scores = []
    for i, q in enumerate(queries):
        if q not in ground_truth:
            continue
        relevant = ground_truth[q]
        retrieved = search_indices[i]
        for k in k_values:
            results[f"hits@{k}"].append(1 if relevant & set(retrieved[:k]) else 0)
        for rank, idx in enumerate(retrieved, 1):
            if idx in relevant:
                mrr_scores.append(1.0 / rank)
                break
        else:
            mrr_scores.append(0.0)
    print(f"Evaluation complete. MRR: {np.mean(mrr_scores):.4f}")
    return {k: np.mean(v) for k, v in results.items()} | {"mrr": np.mean(mrr_scores)}

def run_pipeline_for_model(model_name, model_path, df_sampled, selected_queries, df_products_text, ground_truth):
    print(f"\n Running pipeline for model: {model_name} ")
    model = SentenceTransformer(model_path)

    # Product embeddings
    product_embeddings = generate_embeddings(df_products_text, model)

    # Query embeddings
    print(f"Generating query embeddings for {len(selected_queries)} queries...")
    query_embeddings = model.encode(selected_queries, batch_size=32, convert_to_numpy=True).astype(np.float32)

    # Search
    index = build_search_index(product_embeddings)
    _, indices = perform_search(index, query_embeddings)

    # Optional re-ranking
    if USE_RERANKER:
        indices = rerank_results(selected_queries, indices, df_products_text)

    # Evaluate
    results = evaluate(indices, selected_queries, ground_truth)
    print(f"Completed model: {model_name} \n")
    return results

def run_comparison():
    datasets = read_input_files()
    df_examples = datasets["examples"]
    df_products = datasets["products"]

    df_filtered = filter_examples(df_examples)
    df_sampled, selected_queries = sample_queries_and_rows(df_filtered)

    unique_product_ids = df_sampled['product_id'].unique()
    df_products_filtered = df_products[df_products['product_id'].isin(unique_product_ids)]
    df_products_text = create_product_text(df_products_filtered)

    ground_truth = create_ground_truth(df_sampled, df_products_text)

    all_results = {}
    for model_name, model_path in MODELS.items():
        res = run_pipeline_for_model(model_name, model_path, df_sampled, selected_queries, df_products_text, ground_truth)
        all_results[model_name] = res

    df_results = pd.DataFrame(all_results).T
    print("\nFinal Model Comparison ")
    print(df_results.to_string(float_format="%.4f"))
    return df_results

comparison_results = run_comparison()

